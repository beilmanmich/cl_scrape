{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Craigslist Apartment Scrape | August 2017 | Author: https://github.com/beilmanmich"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7.13 |Anaconda custom (x86_64)| (default, Dec 20 2016, 23:05:08) \n",
      "[GCC 4.2.1 Compatible Apple LLVM 6.0 (clang-600.0.57)]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Craigslist Apartment Listing Scrape\n",
    "I'm moving! As a result, I wanted to explore how I could automate regular searches of Craigslist, a popular user run website that lists apartments, sublets and house share options based on geographic pages.\n",
    "\n",
    "In this notebook, I'll show you how to make a simple query on Craigslist using some nifty python modules. You can take advantage of all the structure data that exists on webpages to collect interesting datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to figure out how to submit a query to Craigslist. As with many websites, one way you can do this is simply by constructing the proper URL and sending it to Craigslist. Here's a sample URL that is returned after manually typing in a search to Craigslist:\n",
    "\n",
    "https://denver.craigslist.org/search/apa?hasPic=1&max_price=1200&availabilityMode=0&housing_type=1&housing_type=2&housing_type=6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the above query string lists several search criteria \"=\", you can play around with the search options on the left navbar to decipher a pattern for the URL. Please note, this tutorial will only search listings with images (`hasPic=1`), this serves as a good proxy for listing quality (CL is prone to scams!).\n",
    "\n",
    "![CL Params](./png/query_params.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, as we can see, our search criteria is reflected in the URL:\n",
    "\n",
    "Base URL (CL apartments in Denver) - `https://denver.craigslist.org/search/apa?`\n",
    "\n",
    "* hasPic=1 (search only listings with an image)\n",
    "* &max_price=1200 (to a max price of $1200)\n",
    "* &availabilityMode=0 (default)\n",
    "* &housing_type=1 (apartment)\n",
    "* &housing_type=2 (condo)\n",
    "* &housing_type=6 (house)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's grab a single posting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we'll use this knowledge to send some custom URLs to Craigslist. We'll do this using the requests python module, which is really useful for querying websites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In internet lingo, we're posting a *get* requests to the website, which simply says that we'd like to get some information from the Craigslist website. With requests, we can easily create a dictionary that specifies parameters in the URL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_base = 'http://denver.craigslist.org/search/apa'\n",
    "# params = dict(bedrooms=1, housing_type=1, housing_type=2, housing_type=6)\n",
    "\n",
    "#To pass multiple params create a custome Dict (http://docs.python-requests.org/en/master/user/quickstart/#passing-parameters-in-urls)\n",
    "params = {'hasPic':'1','bedrooms': '1', 'housing_type': ['1','2','6']}\n",
    "# params = dict(bedrooms=1, is_furnished=1)\n",
    "\n",
    "rsp = requests.get(url_base, params=params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://denver.craigslist.org/search/apa?bedrooms=1&housing_type=1&housing_type=2&housing_type=6&hasPic=1\n"
     ]
    }
   ],
   "source": [
    "# Note that requests automatically created the right URL:\n",
    "print(rsp.url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Click the above link, make sure results appear, it should look the same as the screen shot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿<!DOCTYPE html>\n",
      "\n",
      "<html class=\"no-js\"><head>\n",
      "    <title>denver apts/housing for rent  - craigslist</title>\n",
      "\n",
      "    <meta name=\"description\" content=\"denver apts/housing for rent  - craigslist\">\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\"/>\n",
      "    <link rel=\"canonical\" href=\"https://denver.craigslist.org/search/apa\">\n",
      "    <link rel=\"alternate\" type=\"application/rss+xml\" href=\"https://denver.craigslist.org/search/apa?format=rss&amp;hasPic=1&amp;housing_type=1&amp;housing_type=2&amp;housing_t\n"
     ]
    }
   ],
   "source": [
    "# We can access the content of the response that Craigslist sent back here:\n",
    "print(rsp.text[:500])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Wow, that's a lot of code.** Remember, websites serve HTML documents, and usually your browser will automatically render this into a nice webpage for you. Since we're doing this with python, we get back the raw text. This is really useful, but how can we possibly parse it all? For this, we'll turn to another great package, BeautifulSoup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "﻿\n",
      "<!DOCTYPE html>\n",
      "<html class=\"no-js\">\n",
      " <head>\n",
      "  <title>\n",
      "   denver apts/housing for rent  - craigslist\n",
      "  </title>\n",
      "  <meta content=\"denver apts/housing for rent  - craigslist\" name=\"description\">\n",
      "   <meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "   <link href=\"https://denver.craigslist.org/search/apa\" rel=\"canonical\">\n",
      "    <link href=\"https://denver.craigslist.org/search/apa?format=rss&amp;hasPic=1&amp;housing_type=1&amp;housing_type=2&amp;housing_type=6&amp;min_bedrooms=1\" rel=\"alternate\" title=\"RSS feed for craigslist | denver apts/housing for rent  - craigslist \" type=\"application/rss+xml\">\n",
      "     <link href=\"https://denver.craigslist.org/search/apa?s=120&amp;hasPic=1&amp;housing_type=1&amp;housing_type=2&amp;housing_type=6&amp;min_bedrooms=1\" rel=\"next\">\n",
      "      <meta content=\"width=device-width,initial-scale=1\" name=\"viewport\">\n",
      "       <link href=\"//www.craigslist.org/styles/cl.css?v=d76fe4376346bd1b2503fb10181051a7\" media=\"all\" rel=\"stylesheet\" type=\"text/css\">\n",
      "        <link hre\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup as bs4\n",
    "\n",
    "# BS4 can quickly parse our text, make sure to tell it that you're giving html\n",
    "html = bs4(rsp.text, 'html.parser')\n",
    "\n",
    "# BS makes it easy to look through a document\n",
    "print(html.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Beautiful soup** lets us quickly search through an HTML document. We can pull out whatever information we want.\n",
    "\n",
    "Scanning through this text, we see a common structure repeated `<p class=\"result-info\">`. This seems to be the container that has information for a single apartment.\n",
    "\n",
    "In BeautifulSoup, we can quickly get all instances of this container:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way to inspect the website elements we want is to use Chrome's handy [DevTools](http://anti-code.com/devtools-cheatsheet/), which allows use to place our cursor over an element and see the corresponding HTML. As we can see in the below screenshot it becomes clear the class structure of CL's website, `p class=\"result-info\"` indicates each resulting link (apartment listing), we can also further drill down to see we can grab other information by class, such as prize, size, BRs, etc.\n",
    "\n",
    "For a better overview of this, please see [Greg Reda](http://www.gregreda.com/2013/03/03/web-scraping-101-with-python/).\n",
    "\n",
    "![CL Class](./png/cl_class.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "# find_all will pull entries that fit your search criteria.\n",
    "# Note that we have to use brackets to define the `attrs` dictionary\n",
    "# Because \"class\" is a special word in python, so we need to give a string.\n",
    "\n",
    "# apts = html.find_all('p', attrs={'class': 'result-info'})\n",
    "\n",
    "apts= html.find_all('p', class_='result-info')\n",
    "\n",
    "print(len(apts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, we've got the 120 results on page one of the CL search. Now let's take a look inside the values of a single apartment listing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p class=\"result-info\">\n",
      " <span class=\"icon icon-star\" role=\"button\">\n",
      "  <span class=\"screen-reader-text\">\n",
      "   favorite this post\n",
      "  </span>\n",
      " </span>\n",
      " <time class=\"result-date\" datetime=\"2017-08-09 07:40\" title=\"Wed 09 Aug 07:40:14 AM\">\n",
      "  Aug  9\n",
      " </time>\n",
      " <a class=\"result-title hdrlnk\" data-id=\"6214332910\" href=\"/apa/d/4-br-3-bath-arvada/6214332910.html\">\n",
      "  4 Br, 3 Bath Arvada\n",
      " </a>\n",
      " <span class=\"result-meta\">\n",
      "  <span class=\"result-price\">\n",
      "   $2900\n",
      "  </span>\n",
      "  <span class=\"housing\">\n",
      "   4br -\n",
      "                    4235ft\n",
      "   <sup>\n",
      "    2\n",
      "   </sup>\n",
      "   -\n",
      "  </span>\n",
      "  <span class=\"result-tags\">\n",
      "   pic\n",
      "   <span class=\"maptag\" data-pid=\"6214332910\">\n",
      "    map\n",
      "   </span>\n",
      "  </span>\n",
      "  <span class=\"banish icon icon-trash\" role=\"button\">\n",
      "   <span class=\"screen-reader-text\">\n",
      "    hide this posting\n",
      "   </span>\n",
      "  </span>\n",
      "  <span aria-hidden=\"true\" class=\"unbanish icon icon-trash red\" role=\"button\">\n",
      "  </span>\n",
      "  <a class=\"restore-link\" href=\"#\">\n",
      "   <span class=\"restore-narrow-text\">\n",
      "    restore\n",
      "   </span>\n",
      "   <span class=\"restore-wide-text\">\n",
      "    restore this posting\n",
      "   </span>\n",
      "  </a>\n",
      " </span>\n",
      "</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# We can see that there's a consistent structure to a listing.\n",
    "# There is a 'time', a 'name', a 'housing' field with size/n_brs, etc.\n",
    "this_appt = apts[30]\n",
    "print(this_appt.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                    4br -\n",
      "                    4235ft2 -\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "# So now we'll pull out a couple of things we might be interested in:\n",
    "# It looks like \"housing\" contains size information. We'll pull that.\n",
    "# Note that `findAll` returns a list, since there's only one entry in\n",
    "# this HTML, we'll just pull the first item.\n",
    "size = this_appt.findAll(attrs={'class': 'housing'})[0].text\n",
    "print(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query split this into n_bedrooms and the size. However, note that sometimes one of these features might be missing. So we'll use an if statement to try and capture this variability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_size_and_brs(size):\n",
    "\n",
    "    split = size.split('-')\n",
    " \n",
    "    if len(split) == 3:\n",
    "        n_brs = split[0].replace('br', '')\n",
    "        this_size = split[1].replace('ft2', '')\n",
    "    elif 'br' in split[0]:\n",
    "        # It's the n_bedrooms\n",
    "        n_brs = split[0].replace('br', '')\n",
    "        this_size = np.nan\n",
    "    elif 'ft2' in split[0]:\n",
    "        # It's the size\n",
    "        this_size = split[0].replace('ft2', '')\n",
    "        n_brs = np.nan\n",
    "    return float(this_size), float(n_brs)\n",
    "\n",
    "this_size, n_brs = find_size_and_brs(size)\n",
    "this_time = this_appt.find('time')['datetime']\n",
    "this_time = pd.to_datetime(this_time)\n",
    "this_price = float(this_appt.find('span', {'class': 'result-price'}).text.strip('$'))\n",
    "this_title = this_appt.find('a', attrs={'class': 'result-title hdrlnk'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4235.0\n",
      "4.0\n",
      "2017-08-09 07:40:00\n",
      "2900.0\n",
      "4 Br, 3 Bath Arvada\n"
     ]
    }
   ],
   "source": [
    "# Now we've got the n_bedrooms, size, price, and time of listing\n",
    "print('\\n'.join([str(i) for i in [this_size, n_brs, this_time, this_price, this_title]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying lots of postings\n",
    "We've made some great headway understanding the query structure, and parsing the results for the key data points we want (size, time, price, title).\n",
    "\n",
    "Now it is time to build a few more functions to parse many listings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define a few helper functions to handle edge cases and make sure that we don't get any errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_prices(results):\n",
    "    prices = []\n",
    "    for rw in results:\n",
    "        price = rw.find('span', {'class': 'result-price'})\n",
    "        if price is not None:\n",
    "            price = float(price.text.strip('$'))\n",
    "        else:\n",
    "            price = np.nan\n",
    "        prices.append(price)\n",
    "    return prices\n",
    "\n",
    "def find_times(results):\n",
    "    times = []\n",
    "    for rw in apts:\n",
    "        if time is not None:\n",
    "            time = time['datetime']\n",
    "            time = pd.to_datetime(time)\n",
    "        else:\n",
    "            time = np.nan\n",
    "        times.append(time)\n",
    "    return times"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to go. We'll loop through all of our locations, and pull a number of entries for each one. We'll use a pandas dataframe to store everything, because this will be useful for future analysis.\n",
    "\n",
    "Note - Craigslist won't take kindly to you querying their server a bunch of times at once. Make sure not to pull too much data too quickly. Another option is to add a delay to each loop iteration. Otherwise your IP might get banned. **ALWAYS PLAY NICE WHEN SCRAPING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now loop through all of CL and store the results\n",
    "results = []  # We'll store the data here\n",
    "# Careful with this...too many queries == your IP gets banned temporarily\n",
    "# search_indices = np.arange(0, 2400, 100)\n",
    "\n",
    "search_indices = np.arange(0, 300, 100)\n",
    "\n",
    "\n",
    "for i in search_indices:\n",
    "        url = 'http://denver.craigslist.org/search/apa'\n",
    "        resp = requests.get(url, params={'bedrooms': 1, 's': i})\n",
    "        txt = bs4(resp.text, 'html.parser')\n",
    "        apts = txt.findAll(attrs={'class': \"result-info\"})\n",
    "        \n",
    "        # Find the size of all entries\n",
    "        size_text = [rw.findAll(attrs={'class': 'housing'})[0].text\n",
    "                     for rw in apts]\n",
    "        sizes_brs = [find_size_and_brs(stxt) for stxt in size_text]\n",
    "\n",
    "        sizes, n_brs = zip(*sizes_brs)  # This unzips into 2 vectors\n",
    "     \n",
    "        # Find the title and link\n",
    "        title = [rw.find('a', attrs={'class': 'result-title hdrlnk'}).text\n",
    "                      for rw in apts]\n",
    "        links = [rw.find('a', attrs={'class': 'result-title hdrlnk'})['href']\n",
    "                 for rw in apts]\n",
    "        \n",
    "        # Find the time\n",
    "        time = [pd.to_datetime(rw.find('time')['datetime']) for rw in apts]\n",
    "        price = find_prices(apts)\n",
    "        \n",
    "        # We'll create a dataframe to store all the data\n",
    "        data = np.array([time, price, sizes, n_brs, title, links])\n",
    "        col_names = ['time', 'price', 'size', 'brs', 'title', 'link']\n",
    "        df = pd.DataFrame(data.T, columns=col_names)\n",
    "        df = df.set_index('time')\n",
    "        \n",
    "        # Add the location variable to all entries\n",
    "        #df['loc'] = loc\n",
    "        results.append(df)\n",
    "        \n",
    "# Finally, concatenate all the results\n",
    "results = pd.concat(results, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll make sure that the right columns are represented numerically:\n",
    "results[['price', 'size', 'brs']] = results[['price', 'size', 'brs']].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>size</th>\n",
       "      <th>brs</th>\n",
       "      <th>title</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-08-09 08:45:00</th>\n",
       "      <td>1803.0</td>\n",
       "      <td>1213.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Pool and Mountain Views in Select Homes, Court...</td>\n",
       "      <td>/apa/d/pool-and-mountain-views-in/6250253301.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-09 08:44:00</th>\n",
       "      <td>1300.0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2 bed/1 bath basement unit all utilities included</td>\n",
       "      <td>/apa/d/2-bed-1-bath-basement-unit/6256648800.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-09 08:43:00</th>\n",
       "      <td>1099.0</td>\n",
       "      <td>665.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Renovated Clubhouse, New Stainless Steel Appli...</td>\n",
       "      <td>/apa/d/renovated-clubhouse-new/6216488683.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-09 08:43:00</th>\n",
       "      <td>1795.0</td>\n",
       "      <td>1245.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Near Park Meadows Mall, Attached and Detached ...</td>\n",
       "      <td>/apa/d/near-park-meadows-mall/6256662656.html</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-08-09 08:42:00</th>\n",
       "      <td>1990.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Location, Community, Quality Living. It Starts...</td>\n",
       "      <td>/apa/d/location-community-quality/6256662029.html</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      price    size  brs  \\\n",
       "time                                       \n",
       "2017-08-09 08:45:00  1803.0  1213.0  2.0   \n",
       "2017-08-09 08:44:00  1300.0  1075.0  2.0   \n",
       "2017-08-09 08:43:00  1099.0   665.0  1.0   \n",
       "2017-08-09 08:43:00  1795.0  1245.0  2.0   \n",
       "2017-08-09 08:42:00  1990.0     NaN  3.0   \n",
       "\n",
       "                                                                 title  \\\n",
       "time                                                                     \n",
       "2017-08-09 08:45:00  Pool and Mountain Views in Select Homes, Court...   \n",
       "2017-08-09 08:44:00  2 bed/1 bath basement unit all utilities included   \n",
       "2017-08-09 08:43:00  Renovated Clubhouse, New Stainless Steel Appli...   \n",
       "2017-08-09 08:43:00  Near Park Meadows Mall, Attached and Detached ...   \n",
       "2017-08-09 08:42:00  Location, Community, Quality Living. It Starts...   \n",
       "\n",
       "                                                                  link  \n",
       "time                                                                    \n",
       "2017-08-09 08:45:00  /apa/d/pool-and-mountain-views-in/6250253301.html  \n",
       "2017-08-09 08:44:00  /apa/d/2-bed-1-bath-basement-unit/6256648800.html  \n",
       "2017-08-09 08:43:00     /apa/d/renovated-clubhouse-new/6216488683.html  \n",
       "2017-08-09 08:43:00      /apa/d/near-park-meadows-mall/6256662656.html  \n",
       "2017-08-09 08:42:00  /apa/d/location-community-quality/6256662029.html  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x11222c250>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEjCAYAAAAsbUY2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110ab5690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = results.hist('price', bins=np.arange(0, 5000, 100))[0, 0]\n",
    "ax.set_title('Price Distribution of Apartments', fontsize=20)\n",
    "ax.set_xlabel('Price', fontsize=18)\n",
    "ax.set_ylabel('Count', fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Finally, we can save this data to a CSV to play around with it later.\n",
    "# We'll have to remove some annoying characters first:\n",
    "import string\n",
    "use_chars = string.ascii_letters +\\\n",
    "    ''.join([str(i) for i in range(10)]) +\\\n",
    "    ' /\\.'\n",
    "results['title'] = results['title'].apply(\n",
    "    lambda a: ''.join([i for i in a if i in use_chars]))\n",
    "\n",
    "results.to_csv('./data/craigslist_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RECAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What did we just do?\n",
    "\n",
    "* We defined the ability to query a website using a custom URL. This is isually the same in structure for a website, but the parameter names will be different.\n",
    "* We sent a *get* request to Craigslist using the *requests* Python module.\n",
    "* We parsed the response using *BeautifulSoup4*.\n",
    "* We then looped through a bunch of apartment listings pulled some relevant data, and comibned it all into a cleaned and usable dataframe with Python's *pandas*.\n",
    "\n",
    "I'll be condensing this walkthrough into a single scipt (.py) file. I'll also be brainstorming how to best capture this data from a time series perspective, hopefully running future analysis of Denver's rental market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS - auto-emailing yourself with notifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, we can use this kind of process to make a bot that scrapes craigslist periodically. This is actually quite simple, as it basically involves pulling the top listings from craigslist, checking this against an \"old\" list, and detecting if there's anything new that has popped up since the last time you checked.\n",
    "\n",
    "Here's a simple script that will get the job done. Once again, don't pull too much data at once, and don't query Craigslist too frequently, or you're gonna get banned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We'll use the gmail module (there really is a module for everything in python)\n",
    "import gmail\n",
    "import time\n",
    "import email"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gm = gmail.GMail('username', 'password')\n",
    "gm.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: You'll need to reconfigure your Gmail account settings to allow access by less secure apps, or you'll need to setup an application-specific password rather than using your account-password. Similarly, you could create a dummy Gmail account.\n",
    "\n",
    "Read more:\n",
    "\n",
    "https://support.google.com/mail/?p=InvalidSecondFactor\n",
    "\n",
    "https://security.google.com/settings/security/apppasswords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define our URL and a query we want to post\n",
    "base_url = 'http://denver.craigslist.org'\n",
    "url = base_url + '/search/roo?query=cap+hill'\n",
    "\n",
    "# This will remove weird characters that people put in titles like ****!***!!!\n",
    "use_chars = string.ascii_letters + ''.join([str(i) for i in range(10)]) + ' '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://denver.craigslist.org/search/roo?query=cap+hill\n"
     ]
    }
   ],
   "source": [
    "print url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n",
      "Found new listing\n"
     ]
    }
   ],
   "source": [
    "#SANDBOX\n",
    "\n",
    "link_list = []  # We'll store the data here\n",
    "link_list_send = []  # This is a list of links to be sent\n",
    "send_list = []  # This is what will actually be sent in the email\n",
    "\n",
    "resp = requests.get(url)\n",
    "txt = bs4(resp.text, 'html.parser')\n",
    "apts = txt.findAll(attrs={'class': \"result-info\"})\n",
    "\n",
    "# We're just going to pull the title and link\n",
    "for apt in apts:\n",
    "    title = apt.find_all('a', attrs={'class': 'result-title hdrlnk'})[0]\n",
    "    name = ''.join([i for i in title.text if i in use_chars])\n",
    "    link = title.attrs['href']\n",
    "    if link not in link_list and link not in link_list_send:\n",
    "        print('Found new listing')\n",
    "        link_list_send.append(link)\n",
    "        send_list.append(str(name) + '  -  ' + base_url+link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'/roo/d/master-bedroom-available-in/6252891210.html', u'/roo/d/2-bedrooms-available-in-cap/6244607325.html', u'/roo/d/room-available-in-cap-hill/6224095429.html', u'/roo/d/spacious-bedroom-available-in/6249185296.html', u'/roo/d/private-bed-and-bath-in-cap/6237469650.html', u'/roo/d/1bdrm-in-renovated-cap-hill/6246738011.html', u'/roo/d/amazing-location-1bdrm-in/6229263531.html', u'/roo/d/roommate-uptown-cap-hill/6213416199.html', u'/roo/d/cap-hill-room-for-rent/6236887925.html', u'/roo/d/2-bed-2-bath-apartment-gov/6233941247.html', u'/roo/d/1-br-in-2br-apartment-in-cap/6207755782.html', u'/roo/d/room-in-2br-apt-cap-hill/6232993956.html', u'/roo/d/2-br-1-kit-1-fb-basement/6196193120.html', u'/roo/d/cap-hill-one-room-for-rent/6219832305.html', u'/roo/d/450-looking-for-roommate-in/6178076581.html', u'/roo/d/top-floor-mansion-lrg-room/6256550665.html', u'/roo/d/unique-butlers-quarters/6245897504.html', u'/roo/d/410-nice-room-available-in-2/6244692946.html', u'/roo/d/master-bedroom-for-rent-in/6241979418.html', u'/roo/d/1-bedroom-need-roomie/6247191478.html', u'/roo/d/room-in-denver-bungalow/6252436842.html', u'/roo/d/roommate-needed-city-park/6252445545.html', u'/roo/d/cozy-denver-bungalow-seeks/6252440830.html', u'/roo/d/room-for-rent-august-move-in/6241394951.html', u'/roo/d/410-nice-room-available-in-2/6250680500.html', u'/roo/d/room-for-rent-sept-1/6245514169.html', u'/roo/d/room-for-rent-in-downtown/6245201959.html', u'/roo/d/cap-hill-apt-share-for-female/6208985246.html', u'/roo/d/looking-for-responsible/6243945713.html', u'/roo/d/unique-butlers-quarters/6203132296.html', u'/roo/d/roommate-wanted-cap-hill/6207033147.html', u'/roo/d/looking-for-someone-to/6232932258.html', u'/roo/d/looking-for-roommate-in-the/6174135919.html', u'/roo/d/cap-hill-roommate-wanted/6203715245.html', u'/roo/d/looking-to-move-in-new-apt-a/6228206307.html', u'/roo/d/serious-inquiry-only-bedroom/6251622802.html', u'/roo/d/seeking-roommate-1150-one/6217655394.html', u'/roo/d/cheap-apartment-room-in-cap/6199951049.html', u'/roo/d/1-room-1-month-available-cap/6199761027.html', u'/roo/d/1-bed-bath-looking-4-chill/6236138839.html', u'/roo/d/looking-for-3rd-roommate-in/6187435320.html', u'/roo/d/1-bed-1-bath-in-cap-hill/6173678418.html', u'/roo/d/iso-room-for-rent-or/6206641817.html', u'/roo/d/seeking-roommate/6256172262.html', u'/roo/d/2bed-1bath-1400sqft-house/6241737734.html', u'/roo/d/room-in-secure-building/6241704407.html', u'/roo/d/looking-for-new-roommate-near/6234621902.html', u'/roo/d/wanted-roomate-to-share-cap/6192810272.html', u'/roo/d/roommate-wanted-in-modern-cap/6192738473.html', u'https://fortcollins.craigslist.org/roo/d/room-available-8-1-old/6220553215.html']\n"
     ]
    }
   ],
   "source": [
    "print link_list_send"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'Master bedroom available in awesome Cap Hill apartment  -  http://denver.craigslist.org/roo/d/master-bedroom-available-in/6252891210.html', u'2 bedrooms available in Cap Hill duplex  -  http://denver.craigslist.org/roo/d/2-bedrooms-available-in-cap/6244607325.html', u'Room Available in Cap Hill House 900  -  http://denver.craigslist.org/roo/d/room-available-in-cap-hill/6224095429.html', u'Spacious Bedroom Available in Cap Hill Home  -  http://denver.craigslist.org/roo/d/spacious-bedroom-available-in/6249185296.html', u'Private bed and bath in Cap Hill  available ASAP  -  http://denver.craigslist.org/roo/d/private-bed-and-bath-in-cap/6237469650.html', u'1bdrm in renovated Cap Hill condo avail Sept Amazing location  -  http://denver.craigslist.org/roo/d/1bdrm-in-renovated-cap-hill/6246738011.html', u'Amazing location 1bdrm in renovated Cap Hill condo avail Sept  -  http://denver.craigslist.org/roo/d/amazing-location-1bdrm-in/6229263531.html', u'Roommate uptowncap hill  -  http://denver.craigslist.org/roo/d/roommate-uptown-cap-hill/6213416199.html', u'Cap Hill room for rent  -  http://denver.craigslist.org/roo/d/cap-hill-room-for-rent/6236887925.html', u'2 Bed  2 Bath Apartment  Gov Park  S Cap Hill  -  http://denver.craigslist.org/roo/d/2-bed-2-bath-apartment-gov/6233941247.html', u'1 BR in 2BR Apartment in Cap Hill Available for Rent  -  http://denver.craigslist.org/roo/d/1-br-in-2br-apartment-in-cap/6207755782.html', u'Room in 2BR apt CAP HILL  avail early Sept  -  http://denver.craigslist.org/roo/d/room-in-2br-apt-cap-hill/6232993956.html', u'2 BR 1 KIT 1 FB Basement apartment in Cap Hill or houshold help  -  http://denver.craigslist.org/roo/d/2-br-1-kit-1-fb-basement/6196193120.html', u'Cap Hill one room for rent basement apartment  -  http://denver.craigslist.org/roo/d/cap-hill-one-room-for-rent/6219832305.html', u'450  LOOKING FOR A ROOMMATE IN THE CAP HILL NEIGHBORHOOD  -  http://denver.craigslist.org/roo/d/450-looking-for-roommate-in/6178076581.html', u'Top floor mansion lrg room furnishedAvailable in September  -  http://denver.craigslist.org/roo/d/top-floor-mansion-lrg-room/6256550665.html', u'Unique Butlers Quarters Apartment Utilities included  -  http://denver.craigslist.org/roo/d/unique-butlers-quarters/6245897504.html', u'410   NICE ROOM AVAILABLE IN 2 BEDROOM APARTMENT  -  http://denver.craigslist.org/roo/d/410-nice-room-available-in-2/6244692946.html', u'Master bedroom for rent in charming five points 3br townhouse  Sept  -  http://denver.craigslist.org/roo/d/master-bedroom-for-rent-in/6241979418.html', u'1 bedroom need Roomie  -  http://denver.craigslist.org/roo/d/1-bedroom-need-roomie/6247191478.html', u'Room in Denver Bungalow available Immediately  -  http://denver.craigslist.org/roo/d/room-in-denver-bungalow/6252436842.html', u'Roommate Needed City Park  -  http://denver.craigslist.org/roo/d/roommate-needed-city-park/6252445545.html', u'Cozy Denver Bungalow Seeks Roommate  -  http://denver.craigslist.org/roo/d/cozy-denver-bungalow-seeks/6252440830.html', u'Room for Rent August move in  -  http://denver.craigslist.org/roo/d/room-for-rent-august-move-in/6241394951.html', u'410  NICE ROOM AVAILABLE IN 2 BEDROOM APARTMENT  -  http://denver.craigslist.org/roo/d/410-nice-room-available-in-2/6250680500.html', u'Room for Rent Sept 1  -  http://denver.craigslist.org/roo/d/room-for-rent-sept-1/6245514169.html', u'Room for rent in Downtown Denver Move in end of August  -  http://denver.craigslist.org/roo/d/room-for-rent-in-downtown/6245201959.html', u'Cap hill apt share for female  -  http://denver.craigslist.org/roo/d/cap-hill-apt-share-for-female/6208985246.html', u'Looking for Responsible roommate  -  http://denver.craigslist.org/roo/d/looking-for-responsible/6243945713.html', u'Unique Butlers Quarters Apartment Utilities included  -  http://denver.craigslist.org/roo/d/unique-butlers-quarters/6203132296.html', u'Roommate wanted Cap Hill  -  http://denver.craigslist.org/roo/d/roommate-wanted-cap-hill/6207033147.html', u'Looking for someone to replace me on lease  -  http://denver.craigslist.org/roo/d/looking-for-someone-to/6232932258.html', u'Looking for a roommate in the cap hill neighborhood  -  http://denver.craigslist.org/roo/d/looking-for-roommate-in-the/6174135919.html', u'Cap hill roommate wanted  -  http://denver.craigslist.org/roo/d/cap-hill-roommate-wanted/6203715245.html', u'Looking to move in a new apt w a chill young professional Female  -  http://denver.craigslist.org/roo/d/looking-to-move-in-new-apt-a/6228206307.html', u'SERIOUS INQUIRY ONLYBEDROOM  PRIVATE BATH IN 2BDRM APT  -  http://denver.craigslist.org/roo/d/serious-inquiry-only-bedroom/6251622802.html', u'SEEKING ROOMMATE 1150  One Bedroom For Rent In 2 Bed 2 Bath  -  http://denver.craigslist.org/roo/d/seeking-roommate-1150-one/6217655394.html', u'Cheap Apartment room in Cap hill  -  http://denver.craigslist.org/roo/d/cheap-apartment-room-in-cap/6199951049.html', u'1 room 1 month available Cap Hill  -  http://denver.craigslist.org/roo/d/1-room-1-month-available-cap/6199761027.html', u'1 BEDBATH  LOOKING 4 A CHILL DOG LOVING ROOMIE  -  http://denver.craigslist.org/roo/d/1-bed-bath-looking-4-chill/6236138839.html', u'Looking for 3rd roommate in Denver  -  http://denver.craigslist.org/roo/d/looking-for-3rd-roommate-in/6187435320.html', u'1 bed1 bath in Cap Hill apartment  immediate availability  -  http://denver.craigslist.org/roo/d/1-bed-1-bath-in-cap-hill/6173678418.html', u'ISO Room for Rent OR Roommates for August 1 Movein  -  http://denver.craigslist.org/roo/d/iso-room-for-rent-or/6206641817.html', u'seeking roommate  -  http://denver.craigslist.org/roo/d/seeking-roommate/6256172262.html', u'2bed 1bath 1400sqft house  -  http://denver.craigslist.org/roo/d/2bed-1bath-1400sqft-house/6241737734.html', u'Room in Secure Building  -  http://denver.craigslist.org/roo/d/room-in-secure-building/6241704407.html', u'Looking for a new roommate near Cheeseman Park  -  http://denver.craigslist.org/roo/d/looking-for-new-roommate-near/6234621902.html', u'WANTED Roomate to Share Cap Hill Condo  -  http://denver.craigslist.org/roo/d/wanted-roomate-to-share-cap/6192810272.html', u'Roommate wanted in modern Cap Hill condo  Garage Parking included  -  http://denver.craigslist.org/roo/d/roommate-wanted-in-modern-cap/6192738473.html', u'Room Available 81  Old TownCap Hills Area Utilities Included  -  http://denver.craigslist.orghttps://fortcollins.craigslist.org/roo/d/room-available-8-1-old/6220553215.html']\n"
     ]
    }
   ],
   "source": [
    "print send_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're going to build a `while True:` loop (eventually the below code chunk is stored as an executable `.py` script). Read more about `while True:` logic [here](https://wiki.python.org/moin/WhileLoop)\n",
    "\n",
    "We're just simply going to let this script run 24/7 in the background, thus allowing the cache to go uniterrupted and allowing the bot to perform it's simple job:\n",
    "\n",
    "**Email whenever a new listing appears with our search criteria.**\n",
    "\n",
    "Again, play nice with CL, your IP can get a ban if you scrape too much. You can alter the `sleep_amt` intervals and the end of the loop below to play nicely and stay on top of things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Careful with this...too many queries == your IP gets banned temporarily\n",
    "\n",
    "link_list = []  # We'll store the data here\n",
    "link_list_send = []  # This is a list of links to be sent\n",
    "send_list = []  # This is what will actually be sent in the email\n",
    "\n",
    "# We're just going to pull the title and link\n",
    "while True:\n",
    "    resp = requests.get(url)\n",
    "    txt = bs4(resp.text, 'html.parser')\n",
    "    apts = txt.findAll(attrs={'class': \"result-info\"})\n",
    "    # We're just going to pull the title and link\n",
    "    for apt in apts:\n",
    "        title = apt.find_all('a', attrs={'class': 'result-title hdrlnk'})[0]\n",
    "        name = ''.join([i for i in title.text if i in use_chars])\n",
    "        link = title.attrs['href']\n",
    "        if link not in link_list and link not in link_list_send:\n",
    "            print('Found new listing')\n",
    "            link_list_send.append(link)\n",
    "            send_list.append(str(name) + '  -  ' + base_url+link)\n",
    "\n",
    "        # Flush the cache if we've found new entries\n",
    "        if len(link_list_send) > 0:\n",
    "            print('Sending mail!')\n",
    "            msg = '\\n'.join(send_list)\n",
    "            m = email.message.Message()\n",
    "            m.set_payload(msg)\n",
    "            gm.send(m, ['beilman.mich@gmail.com'])\n",
    "            link_list += link_list_send\n",
    "            link_list_send = []\n",
    "            send_list = []\n",
    "\n",
    "        # Sleep a bit so CL doesn't ban us\n",
    "        sleep_amt = np.random.randint(60, 120)\n",
    "        time.sleep(sleep_amt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And there you have it, a simple Craigslist Bot. [Automate the boring stuff](https://automatetheboringstuff.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: the first time you run your Bot you may receive a lot of emails (if you have a broad search criteria like mine), let the Bot run for a few days to really see how well it does!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
